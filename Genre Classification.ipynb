{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title: Exploring Customer Reviews for Music Genre Classification\n",
    "\n",
    "Tutorial notebook prepared by Sergio Oramas\n",
    "\n",
    "Oramas, S., Espinosa-Anke L., Lawlor A., Serra X., & Saggion H. (2016). Exploring Customer Reviews for Music Genre Classification and Evolutionary Studies. 17th International Society for Music Information Retrieval Conference (ISMIR16).\n",
    "\n",
    "PhD thesis:\n",
    "http://sergiooramas.com/phd-thesis/\n",
    "slides for the thesis presentation:\n",
    "https://www.slideshare.net/soramas/phd-thesis-knowledge-extraction-and-representation-learning-for-music-recommendation-and-classification\n",
    "\n",
    "NLP4MIR Tutorial with slides and video:\n",
    "https://www.upf.edu/web/mdm-dtic/tutorial-natural-language-processing-for-music-information-retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ipython notebook Python3 version for https://github.com/sergiooramas/music-genre-classification\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "import json\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading and unzipping data\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import os, sys\n",
    "#Initialization\n",
    "url='https://sites.google.com/site/mirspring2018/resources/genre_classification_data.zip?attredirects=0&d=1'\n",
    "filename='genre_classification_data.zip'\n",
    "#Downloading the zip file from the url\n",
    "if not os.path.exists(filename):\n",
    "    urllib.request.urlretrieve(url,filename)\n",
    "    #Unzipping\n",
    "    zip_ref = zipfile.ZipFile(filename, 'r')\n",
    "    zip_ref.extractall()\n",
    "    zip_ref.close()\n",
    "    print('Data downloaded and unzipped')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Rap & Hip-Hop', 'R&B', 'Dance & Electronic', 'Alternative Rock', 'Latin Music', 'New Age', 'Metal', 'Jazz', 'Classical', 'Folk', 'Country', 'Pop', 'Rock'])\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "products = json.load(open(\"dataset_classification.json\",\"r\"))\n",
    "genre_products = dict()\n",
    "for id, product in products.items():\n",
    "    genre_products.setdefault(product['genre'],[]).append(id)\n",
    "\n",
    "categories = genre_products.keys()\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or create partitions for cross-validation\n",
    "def partition(lst, n): \n",
    "    division = len(lst) / float(n) \n",
    "    return [ lst[int(round(division * i)): int(round(division * (i + 1)))] for i in xrange(n) ]\n",
    "\n",
    "def create_folds(k,suffix):\n",
    "    test = []\n",
    "    train = []\n",
    "    for i in range(0,k):\n",
    "        test.append(set())\n",
    "        train.append(set())\n",
    "    for genre, ids in genre_products.items():\n",
    "        rnd = ids[:]\n",
    "        random.shuffle(rnd)\n",
    "        folds = partition(rnd, k)\n",
    "        for i, fold in enumerate(folds):\n",
    "            test[i].update(fold)\n",
    "            train[i].update(set(ids).difference(fold))\n",
    "    for i in range(0,k):\n",
    "        ftr = open(\"evaluation/train_\"+suffix+str(i)+\".csv\",\"w\")\n",
    "        ftr.write(\"\\n\".join(list(train[i])))\n",
    "        fts = open(\"evaluation/test_\"+suffix+str(i)+\".csv\",\"w\")\n",
    "        fts.write(\"\\n\".join(list(test[i])))\n",
    "    return train, test\n",
    "\n",
    "def load_folds(k,suffix):\n",
    "    test = []\n",
    "    train = []\n",
    "    for i in range(0,k):\n",
    "        ftr = open(\"evaluation/train_\"+suffix+str(i)+\".csv\",\"r\")\n",
    "        train.append(set(ftr.read().splitlines()))\n",
    "        fts = open(\"evaluation/test_\"+suffix+str(i)+\".csv\",\"r\")\n",
    "        test.append(set(fts.read().splitlines()))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(train,test,features):\n",
    "    # Ground truth\n",
    "    y_train = [products[id]['genre'] for id in train]\n",
    "    y_test = [products[id]['genre'] for id in test]\n",
    "    \n",
    "    X_train_d = dict()\n",
    "    X_test_d = dict()  \n",
    "    \n",
    "    if 'bow' in features:\n",
    "        # Create bag-of-words matrix\n",
    "        vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english', ngram_range=(1,2), analyzer='word')\n",
    "        data_train = [products[id]['all_text'] for i,id in enumerate(train)]\n",
    "        data_test = [products[id]['all_text'] for i,id in enumerate(test)]\n",
    "        X_train_d['bow'] = vectorizer.fit_transform(data_train)\n",
    "        X_test_d['bow'] = vectorizer.transform(data_test)\n",
    "    if 'semantic' in features:\n",
    "        # Create bag-of-categories matrix\n",
    "        semantic_data = json.load(open(\"semantic_features.json\"))\n",
    "        data_train = []\n",
    "        data_test = []\n",
    "        for id in train:\n",
    "            entities = \" \".join([str(e) for e in semantic_data[id]['entities']])\n",
    "            categories = \" \".join(semantic_data[id]['categories'])\n",
    "            data_train.append(entities + \" \" + categories)\n",
    "        for id in test:\n",
    "            entities = \" \".join([str(e) for e in semantic_data[id]['entities']])\n",
    "            categories = \" \".join(semantic_data[id]['categories'])\n",
    "            data_test.append(entities + \" \" + categories)\n",
    "\n",
    "        # Create X matrix bag-of-categories\n",
    "        sem_vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "        X_train_d['semantic'] = sem_vectorizer.fit_transform(data_train)\n",
    "        X_test_d['semantic'] = sem_vectorizer.transform(data_test)\n",
    "    \n",
    "    X_train = X_train_d[features[0]]\n",
    "    X_test = X_test_d[features[0]]\n",
    "    for i in range(1,len(features)):\n",
    "        X_train = hstack((X_train,X_train_d[features[i]]),format='csr')\n",
    "        X_test = hstack((X_test,X_test_d[features[i]]),format='csr')\n",
    "\n",
    "    # Classify\n",
    "    clf = LinearSVC(loss='squared_hinge', penalty='l2', dual=False, tol=1e-3)\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    if False:\n",
    "        print(\"classification report:\")\n",
    "        print(metrics.classification_report(y_test, pred,target_names=categories))\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_test, pred))\n",
    "        print()\n",
    "            \n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************\n",
      "bow\n",
      "\n",
      "Running fold 0\n",
      "Running fold 1\n",
      "Running fold 2\n",
      "Running fold 3\n",
      "Running fold 4\n",
      "Mean accuracy: 0.63 Std: 0.02\n",
      "*********************\n",
      "semantic\n",
      "\n",
      "Running fold 0\n",
      "Running fold 1\n",
      "Running fold 2\n",
      "Running fold 3\n",
      "Running fold 4\n",
      "Mean accuracy: 0.65 Std: 0.03\n",
      "*********************\n",
      "bow+semantic\n",
      "\n",
      "Running fold 0\n",
      "Running fold 1\n",
      "Running fold 2\n",
      "Running fold 3\n",
      "Running fold 4\n",
      "Mean accuracy: 0.69 Std: 0.02\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train,test = load_folds(5,\"\")\n",
    "    #train,test = create_folds(5,\"reviews\")\n",
    "    experiments = [['bow'],['semantic'],['bow','semantic']]\n",
    "    for features in experiments:\n",
    "        results = []\n",
    "        print(\"*********************\\n\"+\"+\".join(features)+\"\\n\")\n",
    "        confusion_matrix = np.zeros((13,13))\n",
    "        for i, (train_i, test_i) in enumerate(zip(train,test)):\n",
    "            print(\"Running fold %d\" % i)\n",
    "            results.append(classify(train_i, test_i, features))\n",
    "        print(\"Mean accuracy: %.2f Std: %.2f\" % (np.mean(results), np.std(results)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

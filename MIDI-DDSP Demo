{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of MIDI-DDSP Demo","provenance":[{"file_id":"18kbkyTTgrgXYPaOh1tiICn3_yJGMsUNJ","timestamp":1644940551184},{"file_id":"1QRQe2wxBnEVQHIohrPcyEGeUSjKs3gfj","timestamp":1637895524222}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"aZUBBozs6haz"},"source":["# MIDI-DDSP Demo\n","Here is the demo where you can automatically synthesize MIDI with the proposed model and then edit the note expression controls of each note. This can be seen as a prototype of our system where users can interact with the model and create the desired music audio together.\n","\n","[MIDI-DDSP ICLR paper]()\n","\n","[Audio Examples]()\n","\n","<img src=\"https://midi-ddsp.github.io/pics/midi-ddsp-diagram-hori.png\" alt=\"MIDI-DDSP\" width=\"700\">\n","\n","### Instructions for running:\n","\n","* Make sure to use a GPU runtime, click:  __Runtime >> Change Runtime Type >> GPU__\n","* Press ▶️ on the left of each of the cells\n","* View the code: Double-click any of the cells\n","* Hide the code: Double click the right side of the cell\n"]},{"cell_type":"code","metadata":{"cellView":"form","id":"dO4EmHiR3H70"},"source":["#@title #Install Dependencies, Import Code and Setup Models\n","\n","#@markdown Run this cell to install dependencies, import codes, \n","#@markdown setup utility functions and load MIDI-DDSP model weights.\n","#@markdown Running this cell could take a while.\n","\n","!pip install -q ddsp pretty_midi librosa pandas music21\n","\n","!pip install -q git+https://github.com/lukewys/qgrid.git\n","\n","!gdown -q --id 1HbS2fQItqIeeTqalVd65qvw8PeuvYSYz\n","!unzip -q midi_ddsp_model_weights_urmp_9_10.zip\n","# !git clone -q https://github.com/magenta/midi-ddsp.git\n","! git clone -q -b initial-updates https://github.com/lukewys/midi-ddsp\n","!wget -q https://keymusician01.s3.amazonaws.com/FluidR3_GM.zip\n","!unzip -q FluidR3_GM.zip\n","\n","# Ignore a bunch of deprecation warnings\n","import sys\n","sys.path.append('./midi-ddsp')\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import os\n","import librosa\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow.compat.v2 as tf\n","import pandas as pd\n","import qgrid\n","import music21\n","from IPython.display import Javascript\n","import IPython.display as ipd\n","from google.colab import output\n","output.enable_custom_widget_manager()\n","\n","from utils.training_utils import set_seed, get_hp\n","from hparams_synthesis_generator import hparams as hp\n","from midi_ddsp.get_model import get_model, get_fake_data\n","import train_expression_generator\n","from midi_ddsp.expression_generator import ExpressionGenerator\n","from utils.audio_io import save_wav\n","from utils.midi_synthesis_utils import synthesize_mono_midi, synthesize_bach\n","from midi_ddsp_synthesize import synthesize_midi\n","from utils.inference_utils import conditioning_df_to_audio, get_process_group\n","from data_handling.instrument_name_utils import INST_NAME_TO_ID_DICT, INST_NAME_LIST\n","\n","set_seed(1234)\n","sample_rate = 16000\n","\n","synthesis_generator_path = r'./midi_ddsp_model_weights_urmp_9_10/synthesis_generator/50000'\n","hp_dict = get_hp(os.path.join(os.path.dirname(synthesis_generator_path), 'train.log'))\n","for k, v in hp_dict.items():\n","    setattr(hp, k, v)\n","\n","synthesis_generator = get_model(hp)\n","synthesis_generator._build(get_fake_data(hp))\n","synthesis_generator.load_weights(synthesis_generator_path)\n","\n","n_out=6\n","expression_generator_path = r'./midi_ddsp_model_weights_urmp_9_10/expression_generator/5000'\n","expression_generator = ExpressionGenerator(n_out=n_out, nhid=128)\n","fake_data = train_expression_generator.get_fake_data(n_out)\n","expression_generator(fake_data['cond'], out=fake_data['target'], training=True)\n","expression_generator.load_weights(expression_generator_path)\n","\n","print('Done!')\n","\n","def plot_spec(wav, sr, title='', play=True, vmin=-8, vmax=1, save_path=None):\n","    D = np.log(np.abs(librosa.stft(wav, n_fft=512 + 256)))\n","    librosa.display.specshow(D, sr=sr, vmin=vmin, vmax=vmax, cmap='magma')\n","    plt.title(title)\n","    wav = np.clip(wav, -1, 1)\n","    if play:\n","        ipd.display(ipd.Audio(wav, rate=sr))\n","    if save_path:\n","        plt.savefig(save_path)\n","        plt.close()\n","\n","CODE_EXPRESSION_KEY_TO_PAPER_NAME_DICT = {\n","    'amplitude_mean':'volume',\n","    'amplitude_std':'vol_fluc',\n","    'amplitudes_max_pos':'vol_peak_pos',\n","    'vibrato_extend':'vibrato',\n","    'brightness':'brightness',\n","    'attack_level':'attack',\n","    'pitch':'pitch',\n","    'note_length':'note_length',\n","    'onset':'onset',\n","    'offset':'offset',\n","}\n","\n","PAPER_NAME_TO_CODE_EXPRESSION_DICT = {v:k for k,v in CODE_EXPRESSION_KEY_TO_PAPER_NAME_DICT.items()}\n","\n","EDIT_DF_NAME_ORDER = ['volume', 'vol_fluc', 'vol_peak_pos', 'vibrato', 'brightness', 'attack', 'pitch', 'note_length']\n","\n","COND_DF_NAME_ORDER = ['amplitude_mean', 'amplitude_std', 'vibrato_extend', 'brightness', 'attack_level', 'amplitudes_max_pos', 'pitch', 'onset', 'offset', 'note_length']\n","\n","def conditioning_df_to_edit_df(conditioning_df):\n","  edit_df = conditioning_df.copy()\n","  edit_df = edit_df.rename(columns=CODE_EXPRESSION_KEY_TO_PAPER_NAME_DICT)\n","  return edit_df[EDIT_DF_NAME_ORDER]\n","\n","def edit_df_to_conditioning_df(edit_df):\n","  conditioning_df = edit_df.copy()\n","  note_length = conditioning_df['note_length'].values\n","  offset = np.cumsum(note_length)\n","  onset = np.concatenate([[0],offset[:-1]])\n","  conditioning_df['onset']=onset\n","  conditioning_df['offset']=offset\n","  conditioning_df = conditioning_df.rename(columns=PAPER_NAME_TO_CODE_EXPRESSION_DICT)\n","  return conditioning_df[COND_DF_NAME_ORDER]\n","\n","GAIN_ADJUST_DB_DICT = {    \n","    'string_set': {    \n","        'Soprano': 2,\n","        'Alto': 2,\n","        'Tenor': -1,\n","        'Bass': -1,\n","    },\n","    'woodwind_set': {    \n","        'Soprano': 1.5,\n","        'Alto': 1.2,\n","        'Tenor': 0,\n","        'Bass': 1.8,\n","    },\n","    'brasswind_set': {    \n","        'Soprano': 2,\n","        'Alto': 2,\n","        'Tenor': 5.6,\n","        'Bass': 2.9,\n","    },\n","\n","}\n","\n","from google.colab import files\n","def upload_midi():\n","  midi_files = files.upload()\n","  fnames = list(midi_files.keys())\n","  return fnames"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CVRDl2QBf71C"},"source":["## Monophonic MIDI Synthesis"]},{"cell_type":"code","metadata":{"cellView":"form","id":"qkINRV9Tk8BT"},"source":["#@markdown Let's first synthesize a MIDI using MIDI-DDSP! By running this cell without any change, MIDI-DDSP will synthesis the MIDI of \"ode to joy\" using violin. This will take about a minute.\n","\n","#@markdown You can also upload your own MIDI file for MIDI-DDSP to synthesize! (by changing the `midi_file` to \"Upload (.mid)\")\n","#@markdown There are 13 instruments available. You can select instrument in the dropdown menu next to \"instrument\".\n","#@markdown Besides changing instruments and MIDI file, there are two variables you could change to adjust the MIDI synthesis:\n","#@markdown - `pitch_offset`: transpose the MIDI file for `pitch_offset` semitones. (>0 is pitch up, <0 is pitch down). \n","#@markdown Different instrument has different pitch range. Please consider adjusting the `pitch_offset` for different instrument depending on the MIDI file.\n","#@markdown - `speed_rate`: adjust play speed of the MIDI (=1: original speed, >1: faster, <1: slower).\n","\n","#@markdown In this cell, we will only synthesizing a single monophonic track. If you upload multi-track MIDI, only the first track will be used. You can synthesize multi-track MIDI using MIDI-DDSP in the cell below.\n","\n","#@markdown The generation speed on a K80/CPU/TPU would be **5x** realtime, and on a P100 should be approximately **2.4x** realtime (we did not test on P100). That is, one need to wait 24-50 seconds for render a 10 second MIDI.\n","\n","midi_file = 'Ode to Joy' #@param ['Ode to Joy','Upload (.mid)']\n","\n","instrument = \"violin\"  #@param ['violin', 'viola', 'cello', 'double bass', 'flute', 'oboe', 'clarinet', 'saxophone', 'bassoon', 'trumpet', 'horn', 'trombone', 'tuba']\n","\n","pitch_offset =  0#@param {type:\"integer\"}\n","\n","speed_rate =  1#@param {type:\"number\", min:0}\n","\n","if midi_file == 'Ode to Joy':\n","  midi_file = r'./midi-ddsp/midi_example/ode_to_joy.mid'\n","else:\n","  midi_file = upload_midi()[0]\n","\n","instrument_name = instrument\n","\n","instrument_id = INST_NAME_TO_ID_DICT[instrument_name]\n","midi_audio, midi_control_params, midi_synth_params, conditioning_df = synthesize_mono_midi(synthesis_generator, expression_generator, midi_file, instrument_id, output_dir=None, pitch_offset=pitch_offset, speed_rate=speed_rate)\n","plt.figure(figsize=(15,5))\n","plot_spec(midi_audio[0].numpy(), sr=16000)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pVZ0hinyiUp7"},"source":["## Adjusting Note Expression"]},{"cell_type":"markdown","metadata":{"id":"XfPPrdPu5sSy"},"source":["In MIDI-DDSP, six note expression controls are designed and used to control the expressive performance, all in range of [0,1]. You can adjust them to edit the performance aspect of the MIDI synthesis:\n"," - Volume (`volume`): Controls overall volume of a note. (larger value -> larger volume)\n"," - Volume Fluctuation (`vol_fluc`): Controls the extent of the volume changing in a note (crescendo & decrescendo or not). (larger value -> more extensive dynamic changing)\n"," - Volume Peak Position (`vol_peak_pos`): Controls the volume changing in a note (crescendo & decrescendo, together with amplitude_std). (larger value -> later reach maximum volume)\n"," - Attack Noise (`attack_noise`): Controls the extent of note attack (strong or soft). (larger value -> larger attack)\n"," - Brightness (`brightness`): Controls the timbre of a note. (larger value -> brighter / more amplitude on higher harmonics)\n"," - Vibrato (`vibrato`): Controls the extend of the vibrato of a note. (larger value -> larger vibrato extend)\n","\n"," "]},{"cell_type":"code","metadata":{"cellView":"form","id":"5q2DmNEO3H8J"},"source":["#@markdown Run this cell to get an editable table for adjusting note expression.\n","#@markdown The values shown are predicted by note expression control generator.\n","#@markdown Each row is a note. Double click the item in the table and enter the value, click anywhere else to save the change. \n","\n","#@markdown You can also edit the note pitch and length just as editing a MIDI sequence.\n","#@markdown To add a note or remove a note, click \"Add Row\" and \"Remove Row\" on the upper left corner.\n","\n","#@markdown After edit, the table is changed automatically and you can run the synthesize cell below the next cell to synthesize the result. \n","#@markdown **Run this cell again will reset the table to the initial value.**\n","\n","qgrid_widget = qgrid.show_grid(conditioning_df_to_edit_df(conditioning_df), show_toolbar=True)\n","qgrid_widget"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cellView":"form","id":"kBAjQYSW3H8K","scrolled":true},"source":["#@markdown Run this cell to synthesize with edited note expression controls.\n","\n","conditioning_df_changed = edit_df_to_conditioning_df(qgrid_widget.get_changed_df())\n","midi_audio, midi_control_params, midi_synth_params = conditioning_df_to_audio(synthesis_generator, conditioning_df_changed, tf.constant([instrument_id]), display_progressbar=True)\n","plt.figure(figsize=(15,5))\n","plot_spec(midi_audio[0].numpy(), sr=16000)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YWs-peNlsilU"},"source":["## Bach Chorales Synthesis"]},{"cell_type":"code","metadata":{"cellView":"form","colab":{"background_save":true},"id":"6PD7OeeKEYkX"},"source":["#@markdown Besides synthesizing monophonic MIDI, MIDI-DDSP can also synthesizing multi-track MIDI.\n","#@markdown Running this cell to synthesis quartet of [4-part Bach Chorales](https://en.wikipedia.org/wiki/List_of_chorale_harmonisations_by_Johann_Sebastian_Bach).\n","\n","#@markdown You can synthesize any Bach Chorales by typing in piece number to `piece_number` below. A full list of bach chorales available can be found [here](https://github.com/cuthbertLab/music21/tree/master/music21/corpus/bach).\n","\n","#@markdown We provide three quartet settings, string, woodwind and brass wind. You can change the ensemble by selecting from the drop down menu of `ensemble`.\n","\n","\n","piece_number = 'bwv227.1' #@param {type:\"string\"}\n","\n","ensemble = 'string_set' #@param ['string_set', 'woodwind_set', 'brasswind_set']\n","\n","score = music21.corpus.parse(f'bach/{piece_number}')\n","score.write('midi', fp=f'./{piece_number}.mid')\n","midi_file = f'./{piece_number}.mid'\n","midi_audio_mix, midi_audio_all, midi_control_params, midi_synth_params, conditioning_df_all = synthesize_bach(\n","    synthesis_generator, \n","    expression_generator, \n","    midi_file, \n","    quartet_set=ensemble, \n","    pitch_offset=0, \n","    speed_rate=1, \n","    output_dir='./', \n","    gain_adjust_db_dict=GAIN_ADJUST_DB_DICT[ensemble])\n","\n","part_name = list(GAIN_ADJUST_DB_DICT[ensemble].keys())\n","plt.figure(figsize=(15,5))\n","plot_spec(midi_audio_mix, sr=16000, title='Mix')\n","plt.show()\n","\n","for i in range(len(midi_audio_all)):\n","    plt.figure(figsize=(15,5))\n","    plot_spec(midi_audio_all[i], sr=16000, title=part_name[i])\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g0fzbo7Nz-sF"},"source":["## Pitch Bend by Editing Synthesis Parameters"]},{"cell_type":"code","metadata":{"cellView":"form","id":"bEpDheCtEnl4"},"source":["#@markdown Run this cell to generate a pitch bend by editing synthesis parameters.\n","#@markdown You can double-click the cell to see how we do it in the code.\n","#@markdown This is just an example. \n","#@markdown We encourage you to come up with smarter ways to smooth the connection and \n","#@markdown crazy ways to play with the synthesis parameters :).\n","\n","# First define functions to generate pitch bend. \n","# You can come up with your own way of edit pitch or\n","# other synthesis parameters.\n","\n","def get_pitch_bend(start_value, end_value, length, power=4,offset_1=-1,bend_type='exp'):\n","    if bend_type=='exp':\n","        if start_value <= end_value:\n","            value = start_value + (np.power(np.linspace(0.0, 1.0, num=length)+offset_1, power)-offset_1) * (end_value-start_value)\n","        return value\n","    elif bend_type=='linear':\n","        return np.linspace(start_value, end_value, length)\n","\n","# First run the MIDI-DDSP to get the synthesis parameters predicted\n","# You don't need to run this if you already have the synthesis parameter prediction.\n","midi_file = r'./midi-ddsp/midi_example/ode_to_joy.mid'\n","instrument_name = 'violin'\n","instrument_id = INST_NAME_TO_ID_DICT[instrument_name]\n","midi_audio, midi_control_params, midi_synth_params, conditioning_df = synthesize_mono_midi(synthesis_generator, expression_generator, midi_file, instrument_id, output_dir=None, pitch_offset=pitch_offset, speed_rate=speed_rate)\n","\n","# Assume we want to add a pitch bend in the middle of two notes. \n","# The first note ends at frame 368 while the next note start at the frame 375\n","\n","prev_note_off = 368\n","next_note_on = 375\n","f0_ori = midi_synth_params['f0_hz'][0,...,0]\n","amps_ori = midi_synth_params['amplitudes'].numpy()[0,...,0]\n","noise_ori = midi_synth_params['noise_magnitudes'].numpy()\n","hd_ori = midi_synth_params['harmonic_distribution'].numpy()\n","\n","# Edit the f0 to add the pitch bend, starting from \n","# 20 frames before the previous note off to 50 frames after next note on.\n","edit_frame_start = prev_note_off-20\n","edit_frame_end = next_note_on+50\n","edit_frame_duration = edit_frame_end - edit_frame_start\n","\n","f0_changed = tf.concat([f0_ori[:edit_frame_start], \n","            get_pitch_bend(f0_ori[edit_frame_start], \n","                    f0_ori[edit_frame_end], \n","                    (edit_frame_end)-(edit_frame_start), \n","                    power=7, \n","                    bend_type='exp'), \n","            f0_ori[edit_frame_end:]], axis=0)\n","f0_changed = f0_changed[tf.newaxis, ..., tf.newaxis]\n","\n","# For other synthesis parameters, use that from the start of the next note \n","# to replace the connection of notes. \n","# We also need to avoid the onset of the next note, \n","# thus that is the reason we use \"next_note_on+5\" as the start.\n","amps_changed = amps_ori\n","amps_changed[edit_frame_start:edit_frame_end] = amps_ori[next_note_on+5:next_note_on+edit_frame_duration+5]\n","amps_changed = amps_changed[tf.newaxis, ..., tf.newaxis]\n","noise_changed = noise_ori\n","noise_changed[0,edit_frame_start:edit_frame_end,:] = noise_ori[0,next_note_on+5:next_note_on+edit_frame_duration+5,:]\n","hd_changed = hd_ori\n","hd_changed[0,edit_frame_start:edit_frame_end,:] = hd_changed[0,next_note_on+5:next_note_on+edit_frame_duration+5,:]\n","\n","# Resynthesis the audio using DDSP\n","processor_group = get_process_group(midi_synth_params['amplitudes'].shape[1], use_angular_cumsum=True)\n","midi_audio_changed = processor_group({'amplitudes': amps_changed,\n","                        'harmonic_distribution': hd_changed,\n","                        'noise_magnitudes': noise_changed,\n","                        'f0_hz': f0_changed,},\n","                          verbose=False)\n","if synthesis_generator.reverb_module is not None:\n","    midi_audio_changed = synthesis_generator.reverb_module(midi_audio_changed, reverb_number=instrument_id, training=False)\n","\n","plt.figure(figsize=(15,5))\n","# Just play the first 4 seconds\n","plot_spec(midi_audio[0].numpy()[:4*16000], sr=16000, title='Original')\n","plt.show()\n","plt.figure(figsize=(15,5))\n","plot_spec(midi_audio_changed[0].numpy()[:4*16000], sr=16000, title='Add pitch bend')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5xYX-txJ1B13"},"source":["## Multi-track MIDI Synthesis"]},{"cell_type":"code","metadata":{"cellView":"form","colab":{"background_save":true},"id":"IpddFjD97QoV"},"source":["#@markdown Run this cell to upload and synthesize any multi-track MIDI.\n","\n","#@markdown For midi programs that are not supported by MIDI-DDSP, we will use [FluidSynth](https://www.fluidsynth.org/) to synthesize the track.\n","#@markdown For midi programs supported by MIDI-DDSP, it will only synthesize a monophonic performance. \n","#@markdown That is, for a polyphonic track, only a monophonic note sequence will be synthesized.\n","\n","pitch_offset =  0#@param {type:\"integer\"}\n","\n","speed_rate =  1#@param {type:\"number\", min:0}\n","\n","midi_file = upload_midi()[0]\n","\n","output = synthesize_midi(synthesis_generator, expression_generator, midi_file,\n","              pitch_offset=pitch_offset, speed_rate=speed_rate,\n","              output_dir=r'./',\n","              use_fluidsynth=True,\n","              sf2_path='./FluidR3_GM.sf2',\n","              display_progressbar=True)\n","\n","plot_spec(output['midi_audio_mix'], sr=16000, title='Mix')\n","\n","for i in range(len(output['stem_audio'])):\n","    plt.figure(figsize=(15,5))\n","    plot_spec(output['stem_audio'][i], sr=16000, title=f'Track {i}')\n","    plt.show()"],"execution_count":null,"outputs":[]}]}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Musical Instrument Recognition in Solo-Instrument Recordings\n",
    "\n",
    "### MIR Course, March 2018\n",
    "\n",
    "#### A presentation by Venkatesh Shenoy Kadandale, 2017-18 SMC Master Student "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "To classify musical instrument sounds from solo recordings of 'bass guitar' and 'piccolo' categories. Focus will be on feature selection and classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Subset of Good-Sounds Dataset. Here's the [link](https://www.upf.edu/web/mtg/good-sounds?sid=395) to the complete dataset. The original dataset is provided with a [CC BY-NC 4.0 license](). I have used only a subset of this dataset for this task: \n",
    "\n",
    "-  50 Bass Guitar sounds (0000.wav to 0049.wav from good-sounds/sound_files/bass_alejandro_recordings/neumann)\n",
    "\n",
    "-  50 Piccolo sounds (0000.wav to 0049.wav from good-sounds/sound_files/piccolo_irene_recordings/neumann)\n",
    "\n",
    "This subset is temporarily made available [here](https://drive.google.com/open?id=1xfkq7MYGM0otQOAuwmE8gNMl70drvQkq).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the imports\n",
    "import os\n",
    "import urllib\n",
    "import zipfile\n",
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import essentia\n",
    "import essentia.standard as es\n",
    "import pandas as pd #python library for data manipulation and analysis\n",
    "import seaborn as sns; # for visualizing data\n",
    "\n",
    "from sklearn import svm #libraries for machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "#external .py files\n",
    "import download_file_from_google_drive #for downloading big files from google drive\n",
    "import confirm_prompt #for confirming user action \n",
    "import json_flattener #for flatenning jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [NOTE] Please set the path to dataset here(this is the path to directory where the genre folders {cla, dan ... spe} will be moved in)\n",
    "path_to_dataset='../../../data/instruments/'\n",
    "\n",
    "if not os.path.exists(path_to_dataset):\n",
    "    os.umask(0) #To mask the permission restrictions on new files/directories being created\n",
    "    os.makedirs(path_to_dataset,0o777) # 0o777 gives us full permissions for the folder\n",
    "\n",
    "# Prompt to know if you want to skip downloading the dataset\n",
    "skip_dataset_download=confirm_prompt.confirm(prompt='Would you like to skip downloading the data? \\nEnter \\'y\\' if you already have dataset and \\'n\\' to download the dataset.\\n [NOTE] : Downloading the dataset using this notebook can take up to 2 minutes.\\n')\n",
    "if(not skip_dataset_download):\n",
    "    #This block downloads the dataset from google drive\n",
    "    file_id='1xfkq7MYGM0otQOAuwmE8gNMl70drvQkq'\n",
    "    filename=path_to_dataset+\"instruments.zip\"\n",
    "    print(\"Downloading the dataset...\")\n",
    "    download_file_from_google_drive.download_file_from_google_drive(file_id,filename)\n",
    "    print(\"Unzipping the data file.\")\n",
    "    #Unzip the file\n",
    "    zip_ref = zipfile.ZipFile(filename, 'r')\n",
    "    zip_ref.extractall(path_to_dataset)\n",
    "    zip_ref.close()\n",
    "    os.remove(filename)#Removing the zip file\n",
    "    print('Data downloaded and unzipped to: ',path_to_dataset)\n",
    "    \n",
    "# [NOTE] If you already have the dataset, move the instrument folders {flute, trumpet} into path_to_dataset\n",
    "instruments = os.listdir(path_to_dataset)\n",
    "instruments.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A sample from each category\n",
    "import IPython\n",
    "IPython.display.display(IPython.display.Audio('../../../data/instruments/bass/0000.wav'))\n",
    "\n",
    "IPython.display.display(IPython.display.Audio('../../../data/instruments/piccolo/0000.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "\n",
    "We extract all the low level features using Essentia's Music Extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Prompt to know if you want to extract the features now or use the pre-extracted ones\n",
    "skip_json_extraction=confirm_prompt.confirm(prompt='Would you like to skip extraction of feature jsons from the dataset? \\nEnter \\'y\\' if you want to use the pre-extracted jsons and \\'n\\' to start extracting jsons.\\n')\n",
    "\n",
    "if(skip_json_extraction):\n",
    "    #Download the pre-extracted feature jsons\n",
    "    file_id='1KjP1evRzJZMGiRUva8i-_cbRHnrQJTI6'\n",
    "    filename=path_to_dataset+\"instrument_jsons.zip\"\n",
    "    print(\"Downloading the pre-extracted jsons...\")\n",
    "    urllib.request.urlretrieve('http://docs.google.com/uc?id='+file_id,filename)\n",
    "    #Unzip the file\n",
    "    zip_ref = zipfile.ZipFile(filename, 'r')\n",
    "    zip_ref.extractall(path_to_dataset)\n",
    "    zip_ref.close()\n",
    "    os.remove(filename)#Removing the zip file\n",
    "    print('Data downloaded and unzipped to the instrument specific folders.')    \n",
    "else:    \n",
    "    #Extract all the features in json format\n",
    "    for instrument in instruments:\n",
    "        print(\"[Instrument] : \" + instrument)\n",
    "        files=sorted(os.listdir(path_to_dataset+instrument))\n",
    "        print(\"Number of files : \"+str(len(files)))\n",
    "        for file in files:\n",
    "            if(file.endswith('.wav')):\n",
    "                filename=path_to_dataset+instrument+\"/\"+file \n",
    "                print(\"Analysing file : \"+filename)\n",
    "                # Compute all features, aggregate only 'mean' and 'stdev' statistics for all low-level, rhythm and tonal frame features\n",
    "                features, features_frames = es.MusicExtractor(lowlevelSilentFrames='drop',\n",
    "                                                              lowlevelFrameSize=2048,\n",
    "                                                              lowlevelHopSize=1024,\n",
    "                                                              lowlevelStats=['mean', 'stdev'])(filename)\n",
    "                features_frames=[]\n",
    "                es.YamlOutput(filename = filename.replace('.wav','.json'), format='json')(features)\n",
    "                features=[]\n",
    "                filename=[]\n",
    "    print(\"Feature Extraction Completed Successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection \n",
    "\n",
    "We flatten the json and choose the features that we are interested in. Plot graphs? Distributions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedFeatures=sorted(['lowlevel_average_loudness', 'lowlevel_hfc_mean', 'lowlevel_dissonance_mean', 'lowlevel_pitch_salience_mean'])\n",
    "features=['filename','instrument']\n",
    "features.extend(sortedFeatures)\n",
    "\n",
    "# Load data into Pandas Dataframes\n",
    "dictValues={}\n",
    "dfv=pd.DataFrame(dictValues, columns=features)\n",
    "i=0\n",
    "for instrument in instruments:\n",
    "    print(\"Fetching json files from [INSTRUMENT] : \" + instrument)\n",
    "    files=os.listdir(path_to_dataset+instrument)\n",
    "    for fileName in files:\n",
    "        if(fileName.endswith('.json')):\n",
    "            jsonFile = open (path_to_dataset+instrument+\"/\"+fileName,\"r\",encoding=\"utf-8\")\n",
    "            jsonToPython = json.loads(jsonFile.read(), strict=False)\n",
    "            flatJson = json_flattener.flatten_json(jsonToPython)\n",
    "            dictValues[features[0]] = fileName.replace('.json','')\n",
    "            dictValues[features[1]] = instruments.index(instrument)+1\n",
    "            for index in range(2,len(features)):\n",
    "                dictValues[features[index]]=flatJson.get(features[index])\n",
    "            dfv.loc[i]=(dictValues)\n",
    "            i+=1\n",
    "print(\"Features loaded into panda dataframe!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize features to zero mean and unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfv.iloc[:, :2] #seperate out filenames and instrument columns from the rest\n",
    "df2 = dfv.iloc[:, 2:]\n",
    "scaler = StandardScaler() #To standardize the features to zero mean and unit variance\n",
    "df2[df2.columns] = scaler.fit_transform(df2[df2.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segregating Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train_df for training data(80% of dataset) and test_df for test data(20% of dataset).\n",
    "df = pd.concat([df1, df2], axis=1)\n",
    "X = df.iloc[:,2:].as_matrix()\n",
    "y = df.transpose().as_matrix()[1].astype('int')\n",
    "\n",
    "train_df = pd.concat([df.iloc[:35,:],df.iloc[50:85,:]], ignore_index=True)\n",
    "test_df = pd.concat([df.iloc[35:50,:],df.iloc[85:100,:]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=test_df.iloc[:,2:].as_matrix()\n",
    "clf_output = clf.predict(test_data) # storing classifier output - predicted labels\n",
    "gt = test_df.transpose().as_matrix()[1].astype('int') # storing ground truth "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(gt, clf_output)\n",
    "np.set_printoptions(precision=2)\n",
    "class_names=instruments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A seaborn heatmap is used to visualize the confusion matrix\n",
    "sns.set()\n",
    "df_cm = pd.DataFrame(cnf_matrix, index=class_names, columns=class_names)\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=14)\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=14)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "print(\"Classification accuracy : \"+str(100*accuracy_score(gt,clf_output))+\" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Romani Picas O. Dabiri D., Serra X. \"A real-time system for meauring sound goodness in instrumental sounds\" 138th Audio Engineering Society Convention, Warsarw, 2015"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
